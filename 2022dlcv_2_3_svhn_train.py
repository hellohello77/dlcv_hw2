# -*- coding: utf-8 -*-
"""2022dlcv_2_3.ipynb 的副本

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dGva70_Xsx2qplW2s0ugAgyWom94IMXb

"""

"""## Packages"""

# Commented out IPython magic to ensure Python compatibility.
import torch
import PIL
from PIL import Image
import matplotlib.pyplot as plt
import os
from torch.utils.data import DataLoader
import torchvision
from torchvision import models
import torch.nn as nn
import torchvision.transforms as T
import numpy as np
import csv
# print(torch.backends.mps.is_available())
# %matplotlib inline

path_to_datafile = '/content/hw2_data/digits'

# img=Image.open(os.path.join(path_to_datafile, 'p1_data/train_50/0_0.png'))
# plt.imshow(img)
# plt.show()

"""# Dataset

## Dataset
"""

class hw2_3_dataset:
    def __init__(self, filepath, transform):
        self.transform = transform
        self.filepath = filepath
        self.file_list = []
        self.labels = []
        with open(os.path.join(filepath, 'train.csv'), newline='') as csvfile:
          reader = csv.reader(csvfile, delimiter=',')
          for idx, row in enumerate(reader):
            if idx:
              self.file_list.append(row[0])
              self.labels.append(int(row[1]))
    
    def __len__(self):
        return len(self.file_list)
    
    def __getitem__(self, idx):
        img_path = os.path.join(self.filepath, 'data', self.file_list[idx])
        img = Image.open(img_path)
        transformed_img = self.transform(img)
        img.close()
        return transformed_img, self.labels[idx]

class hw2_3_dataset_val:
    def __init__(self, filepath, transform):
        self.transform = transform
        self.filepath = filepath
        self.file_list = []
        self.labels = []
        with open(os.path.join(filepath, 'val.csv'), newline='') as csvfile:
          reader = csv.reader(csvfile, delimiter=',')
          for idx, row in enumerate(reader):
            if idx:
              self.file_list.append(row[0])
              self.labels.append(int(row[1]))
    
    def __len__(self):
        return len(self.file_list)
    
    def __getitem__(self, idx):
        img_path = os.path.join(self.filepath, 'data', self.file_list[idx])
        img = Image.open(img_path)
        transformed_img = self.transform(img)
        img.close()
        return transformed_img, self.labels[idx]

"""## Data Loader"""

import math
img_transform = T.Compose([
    # T.Resize(224),
    T.ToTensor(),
    T.Normalize(mean=[0.485, 0.456, 0.406],
               std=[0.229, 0.224, 0.225])
])
target_domain = 'svhn'
hw2_3_source = hw2_3_dataset(os.path.join(path_to_datafile, 'mnistm'), img_transform)
hw2_3_target = hw2_3_dataset(os.path.join(path_to_datafile, target_domain), img_transform)
hw2_3_test = hw2_3_dataset_val(os.path.join(path_to_datafile, target_domain), img_transform)
BATCH_SIZE = 128
iterations = 300
source_loader = DataLoader(hw2_3_source, batch_size=math.ceil(len(hw2_3_source)/iterations), shuffle=True)
target_loader = DataLoader(hw2_3_target, batch_size=math.ceil(len(hw2_3_target)/iterations), shuffle=True)
test_loader = DataLoader(hw2_3_test, batch_size=BATCH_SIZE, shuffle=False)

"""# Model

## Gradient Reverse
"""

from torch.autograd import Function

class GRL(Function):
    @staticmethod
    def forward(ctx, x, alpha):
        ctx.alpha = alpha
        return x.view_as(x)

    @staticmethod
    def backward(ctx, grad_output):
        output = grad_output.neg() * ctx.alpha
        return output, None

"""## Single DANN"""

class DANN(nn.Module):
    def __init__(self,num_classes=10):
        super(DANN,self).__init__()
        self.features=nn.Sequential(
            nn.Conv2d(3,32,5),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),
            nn.Conv2d(32,48,5),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),
        )
        self.avgpool=nn.AdaptiveAvgPool2d((5,5))
        self.task_classifier=nn.Sequential(
            nn.Linear(48*5*5,100),
            nn.ReLU(inplace=True),
            nn.Linear(100,100),
            nn.ReLU(inplace=True),
            nn.Linear(100,num_classes)
        )
        self.domain_classifier=nn.Sequential(
            nn.Linear(48*5*5,100),
            nn.ReLU(inplace=True),
            nn.Linear(100,2)
        )
        self.GRL=GRL()
    def forward(self,x,alpha):
        x = x.expand(x.data.shape[0], 3, 28, 28)
        x=self.features(x)
        x=self.avgpool(x)
        x=torch.flatten(x,1)
        task_predict=self.task_classifier(x)
        x=GRL.apply(x,alpha)
        domain_predict=self.domain_classifier(x)
        return task_predict,domain_predict

"""## Define Models"""

if(torch.cuda.is_available()):
    device = torch.device("cuda")
else:
    device = torch.device('cpu')
    print('using CPU')
DANN_model = DANN()
if(torch.cuda.is_available()):
    DANN_model = DANN_model.to(device)
else:
    print('WARNING!!!!!!!!!!!!!! MPS CAN\'T BE USED')
domain_loss=nn.CrossEntropyLoss()
task_loss=nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(DANN_model.parameters(), lr=0.001)

"""# Training"""

def get_lambda(epoch, max_epoch):
    p = epoch / max_epoch
    return 2. / (1+np.exp(-10.*p)) - 1.

'''
source: https://github.com/pytorch/examples/blob/main/dcgan/main.py
'''
from tqdm.notebook import tqdm
import math
EPOCH = 100
# lamda = 1
current_best = 0
for epoch in range(EPOCH):
    corrects_C = 0
    corrects_D_src = 0
    corrects_D_tgt = 0
    progress = tqdm(total = iterations)
    # target_iter = iter(target_loader)
    for idx, ((src_images, labels), (tgt_images, _)) in enumerate(zip(source_loader, target_loader)):
        alpha = 0.5*get_lambda(epoch, EPOCH)
        src, labels, tgt = src_images.to(device), labels.to(device), tgt_images.to(device)
        DANN_model.zero_grad()
        src_predict, src_domains = DANN_model(src, alpha)
        src_label_loss = task_loss(src_predict, labels)
        src_domain_loss = domain_loss(src_domains, torch.ones(len(src_domains)).long().cuda())
        
        _, dst_domains = DANN_model(tgt, alpha)
        dst_domain_loss = domain_loss(dst_domains, torch.zeros(len(dst_domains)).long().cuda())

        losses=src_label_loss+src_domain_loss+dst_domain_loss
        losses.backward()
        optimizer.step()

        preds_C = torch.max(src_predict, dim=1)[1]
        corrects_C += torch.sum(preds_C == labels).item()
        preds_D_src = torch.max(src_domains, dim=1)[1]
        corrects_D_src += torch.sum(preds_D_src == torch.ones(len(src_domains)).long().cuda()).item()
        preds_D_tgt = torch.max(dst_domains, dim=1)[1]
        corrects_D_tgt += torch.sum(preds_D_tgt == torch.zeros(len(dst_domains)).long().cuda()).item()
        progress.update(1)
    print(epoch)
    # print(len(hw2_3_source)+len(hw2_3_target))
    # print('total loss: ', Ltot.item())
    print('src_D acc: ', corrects_D_src/len(hw2_3_source))
    print('tgt_D acc: ', corrects_D_tgt/len(hw2_3_target))
    print('C acc: ', corrects_C/len(hw2_3_source))

    DANN_model.eval()
    corrects_test = 0
    for idx, (test_images, labels) in enumerate(test_loader):
        with torch.no_grad():
            
            imgs = test_images.to(device)
            labels = labels.to(device)
            test_predict, test_domains = DANN_model(imgs, alpha = 0.01)
            preds = torch.max(test_predict, dim = 1)[1]
            corrects_test += torch.sum(preds == labels).item()
    
    print('Eval acc: ', corrects_test/len(hw2_3_test))
    if(corrects_test/len(hw2_3_test) > current_best):
      current_best = corrects_test/len(hw2_3_test)
      print('models save')
      torch.save(DANN_model.state_dict(), f'/content/drive/MyDrive/hw2_models/DANN_{epoch+1}.ckpt')
    DANN_model.train()